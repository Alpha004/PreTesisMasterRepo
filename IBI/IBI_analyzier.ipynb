{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALISIS DE DATOS DE INTERVALOS DE LATIDOS DEL CORAZON (IBI)\n",
    "\n",
    "El presente es para analizar los datos de la temperatura de la piel del smartwatch, el cual tiene un procesamiento de datos en 1.25Hz, que serian 1 registros por 0.80 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Pandas y otras librerias\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACIENTE = '001'\n",
    "PATH_FOLDER = 'G:\\\\Dataset\\\\big-ideas-lab-glycemic-variability-and-wearable-device-data-1.1.2\\\\'+PACIENTE+'\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo el CSV\n",
    "ibi_values = pd.read_csv(PATH_FOLDER + 'IBI_'+PACIENTE+'.csv', engine='python', na_values=\"not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>ibi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-13 15:33:22.059328</td>\n",
       "      <td>0.828163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13 15:33:22.934368</td>\n",
       "      <td>0.875040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-13 15:34:21.593303</td>\n",
       "      <td>0.984420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-13 15:34:22.483969</td>\n",
       "      <td>0.890666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-13 15:34:23.421512</td>\n",
       "      <td>0.937543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     datetime       ibi\n",
       "0  2020-02-13 15:33:22.059328  0.828163\n",
       "1  2020-02-13 15:33:22.934368  0.875040\n",
       "2  2020-02-13 15:34:21.593303  0.984420\n",
       "3  2020-02-13 15:34:22.483969  0.890666\n",
       "4  2020-02-13 15:34:23.421512  0.937543"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibi_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266366 entries, 0 to 266365\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   datetime  266366 non-null  object \n",
      " 1    ibi      266366 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "ibi_values.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    266366\n",
       " ibi        266366\n",
       "dtype: int64"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibi_values.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-02-13 15:33:22.059328\n",
       "1    2020-02-13 15:33:22.934368\n",
       "2    2020-02-13 15:34:21.593303\n",
       "3    2020-02-13 15:34:22.483969\n",
       "4    2020-02-13 15:34:23.421512\n",
       "Name: datetime, dtype: object"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibi_values[\"datetime\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con Datetime\n",
    "Lo primero sera convertir los datetime a el formato correcto, ya que lo esta detectando como object, lo siguiente sera colocar como index las fechas y al final agrupar por cada 5 minutos los datos para obtener el promedio y media de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', ' ibi'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convertimos en fechas los datimetimes\n",
    "ibi_values['datetime'] = pd.to_datetime(ibi_values['datetime'])\n",
    "print(ibi_values.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([' ibi'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Se coloca indices como datetime\n",
    "ibi_values = ibi_values.set_index('datetime')\n",
    "print(ibi_values.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos le media, la mediana y demas factores de estadistica\n",
    "\n",
    "En este caso tenemos que obtener el promedio, mediana, max, min, desviacion estandar y quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular los cuartiles 1 y 3 que indican en el paper\n",
    "# \n",
    "def quartiles(x):\n",
    "    return pd.Series([x.quantile(0.25), x.quantile(0.75)], index=['q1', 'q3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado_5min = ibi_values[' ibi'].resample('5min') \n",
    "df_procesado_5min_HR = ibi_values.resample('5min') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1    datetime\n",
       "2020-02-13 15:30:00    0.875040\n",
       "2020-...\n",
       "q3    datetime\n",
       "2020-02-13 15:30:00    0.937543\n",
       "2020-...\n",
       "dtype: object"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear a serie de dataframe de 5 min\n",
    "series5min = quartiles(df_procesado_5min)\n",
    "series5min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean', 'median', 'max', 'min', 'std'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:30:00</th>\n",
       "      <td>0.903166</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>0.828163</td>\n",
       "      <td>0.059910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:35:00</th>\n",
       "      <td>0.849333</td>\n",
       "      <td>0.921917</td>\n",
       "      <td>1.140677</td>\n",
       "      <td>0.468771</td>\n",
       "      <td>0.228782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:40:00</th>\n",
       "      <td>0.930846</td>\n",
       "      <td>0.953169</td>\n",
       "      <td>1.078174</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:45:00</th>\n",
       "      <td>0.953820</td>\n",
       "      <td>0.953169</td>\n",
       "      <td>1.250057</td>\n",
       "      <td>0.562526</td>\n",
       "      <td>0.157979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:50:00</th>\n",
       "      <td>0.937543</td>\n",
       "      <td>0.968794</td>\n",
       "      <td>1.125051</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.098188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:55:00</th>\n",
       "      <td>0.896291</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.281309</td>\n",
       "      <td>0.671906</td>\n",
       "      <td>0.153557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:00:00</th>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.671906</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.058267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:05:00</th>\n",
       "      <td>0.904871</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.093800</td>\n",
       "      <td>0.781286</td>\n",
       "      <td>0.102096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean    median       max       min       std\n",
       "datetime                                                             \n",
       "2020-02-13 15:30:00  0.903166  0.890666  0.984420  0.828163  0.059910\n",
       "2020-02-13 15:35:00  0.849333  0.921917  1.140677  0.468771  0.228782\n",
       "2020-02-13 15:40:00  0.930846  0.953169  1.078174  0.437520  0.159200\n",
       "2020-02-13 15:45:00  0.953820  0.953169  1.250057  0.562526  0.157979\n",
       "2020-02-13 15:50:00  0.937543  0.968794  1.125051  0.734409  0.098188\n",
       "2020-02-13 15:55:00  0.896291  0.875040  1.281309  0.671906  0.153557\n",
       "2020-02-13 16:00:00  0.515649  0.515649  0.671906  0.390643  0.058267\n",
       "2020-02-13 16:05:00  0.904871  0.875040  1.093800  0.781286  0.102096"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos los metodos del dataframe a calcular\n",
    "df_5min = df_procesado_5min.agg(['mean', 'median', 'max', 'min', 'std'])\n",
    "print(df_5min.columns)\n",
    "df_5min = df_5min.fillna(0)\n",
    "df_5min.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean', 'median', 'max', 'min', 'std'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:00:00</th>\n",
       "      <td>0.910574</td>\n",
       "      <td>0.937543</td>\n",
       "      <td>1.281309</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>0.163677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:00:00</th>\n",
       "      <td>0.914551</td>\n",
       "      <td>0.968794</td>\n",
       "      <td>1.234432</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.201014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:00:00</th>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.781286</td>\n",
       "      <td>1.328186</td>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.103357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 18:00:00</th>\n",
       "      <td>0.918940</td>\n",
       "      <td>0.937543</td>\n",
       "      <td>1.312560</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.125242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 19:00:00</th>\n",
       "      <td>0.874715</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.250057</td>\n",
       "      <td>0.359391</td>\n",
       "      <td>0.117019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 20:00:00</th>\n",
       "      <td>0.877129</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.140677</td>\n",
       "      <td>0.546900</td>\n",
       "      <td>0.108340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 21:00:00</th>\n",
       "      <td>0.955519</td>\n",
       "      <td>0.968794</td>\n",
       "      <td>1.296934</td>\n",
       "      <td>0.578151</td>\n",
       "      <td>0.100944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 22:00:00</th>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>1.406314</td>\n",
       "      <td>0.359391</td>\n",
       "      <td>0.079524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 23:00:00</th>\n",
       "      <td>0.915187</td>\n",
       "      <td>0.906291</td>\n",
       "      <td>1.140677</td>\n",
       "      <td>0.406269</td>\n",
       "      <td>0.064902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 00:00:00</th>\n",
       "      <td>0.989850</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>1.296934</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.085531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean    median       max       min       std\n",
       "datetime                                                             \n",
       "2020-02-13 15:00:00  0.910574  0.937543  1.281309  0.437520  0.163677\n",
       "2020-02-13 16:00:00  0.914551  0.968794  1.234432  0.390643  0.201014\n",
       "2020-02-13 17:00:00  0.788136  0.781286  1.328186  0.515649  0.103357\n",
       "2020-02-13 18:00:00  0.918940  0.937543  1.312560  0.390643  0.125242\n",
       "2020-02-13 19:00:00  0.874715  0.875040  1.250057  0.359391  0.117019\n",
       "2020-02-13 20:00:00  0.877129  0.875040  1.140677  0.546900  0.108340\n",
       "2020-02-13 21:00:00  0.955519  0.968794  1.296934  0.578151  0.100944\n",
       "2020-02-13 22:00:00  0.982950  0.984420  1.406314  0.359391  0.079524\n",
       "2020-02-13 23:00:00  0.915187  0.906291  1.140677  0.406269  0.064902\n",
       "2020-02-14 00:00:00  0.989850  0.984420  1.296934  0.734409  0.085531"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lo mismo aplicamos para 1 hora\n",
    "df_procesado_1hora = ibi_values[' ibi'].resample('1h') \n",
    "# Obtenemos el promedio\n",
    "df_1hora = df_procesado_1hora.agg(['mean', 'median', 'max', 'min', 'std'])\n",
    "\n",
    "# Removemos las columnas que no necesitamos por ahora\n",
    "# df_1hora = df_1hora.drop(columns=columns_to_remove)\n",
    "print(df_1hora.columns)\n",
    "df_1hora.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:30:00</th>\n",
       "      <td>0.903166</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>0.828163</td>\n",
       "      <td>0.059910</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>0.937543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:35:00</th>\n",
       "      <td>0.849333</td>\n",
       "      <td>0.921917</td>\n",
       "      <td>1.140677</td>\n",
       "      <td>0.468771</td>\n",
       "      <td>0.228782</td>\n",
       "      <td>0.625028</td>\n",
       "      <td>1.039110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:40:00</th>\n",
       "      <td>0.930846</td>\n",
       "      <td>0.953169</td>\n",
       "      <td>1.078174</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.910197</td>\n",
       "      <td>1.023484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:45:00</th>\n",
       "      <td>0.953820</td>\n",
       "      <td>0.953169</td>\n",
       "      <td>1.250057</td>\n",
       "      <td>0.562526</td>\n",
       "      <td>0.157979</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>1.046923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:50:00</th>\n",
       "      <td>0.937543</td>\n",
       "      <td>0.968794</td>\n",
       "      <td>1.125051</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.098188</td>\n",
       "      <td>0.859414</td>\n",
       "      <td>1.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:55:00</th>\n",
       "      <td>0.896291</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.281309</td>\n",
       "      <td>0.671906</td>\n",
       "      <td>0.153557</td>\n",
       "      <td>0.796911</td>\n",
       "      <td>0.953169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:00:00</th>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.671906</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>0.484397</td>\n",
       "      <td>0.562526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:05:00</th>\n",
       "      <td>0.904871</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.093800</td>\n",
       "      <td>0.781286</td>\n",
       "      <td>0.102096</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>0.960981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:10:00</th>\n",
       "      <td>0.887541</td>\n",
       "      <td>0.906291</td>\n",
       "      <td>1.109426</td>\n",
       "      <td>0.593777</td>\n",
       "      <td>0.191821</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>0.984420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:15:00</th>\n",
       "      <td>0.974003</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>1.000046</td>\n",
       "      <td>0.937543</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.960981</td>\n",
       "      <td>0.992233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean    median       max       min       std  \\\n",
       "datetime                                                                \n",
       "2020-02-13 15:30:00  0.903166  0.890666  0.984420  0.828163  0.059910   \n",
       "2020-02-13 15:35:00  0.849333  0.921917  1.140677  0.468771  0.228782   \n",
       "2020-02-13 15:40:00  0.930846  0.953169  1.078174  0.437520  0.159200   \n",
       "2020-02-13 15:45:00  0.953820  0.953169  1.250057  0.562526  0.157979   \n",
       "2020-02-13 15:50:00  0.937543  0.968794  1.125051  0.734409  0.098188   \n",
       "2020-02-13 15:55:00  0.896291  0.875040  1.281309  0.671906  0.153557   \n",
       "2020-02-13 16:00:00  0.515649  0.515649  0.671906  0.390643  0.058267   \n",
       "2020-02-13 16:05:00  0.904871  0.875040  1.093800  0.781286  0.102096   \n",
       "2020-02-13 16:10:00  0.887541  0.906291  1.109426  0.593777  0.191821   \n",
       "2020-02-13 16:15:00  0.974003  0.984420  1.000046  0.937543  0.032528   \n",
       "\n",
       "                           q1        q3  \n",
       "datetime                                 \n",
       "2020-02-13 15:30:00  0.875040  0.937543  \n",
       "2020-02-13 15:35:00  0.625028  1.039110  \n",
       "2020-02-13 15:40:00  0.910197  1.023484  \n",
       "2020-02-13 15:45:00  0.890666  1.046923  \n",
       "2020-02-13 15:50:00  0.859414  1.000046  \n",
       "2020-02-13 15:55:00  0.796911  0.953169  \n",
       "2020-02-13 16:00:00  0.484397  0.562526  \n",
       "2020-02-13 16:05:00  0.843789  0.960981  \n",
       "2020-02-13 16:10:00  0.843789  0.984420  \n",
       "2020-02-13 16:15:00  0.960981  0.992233  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar los cuartiles en columnas individuales\n",
    "# Obtenemos los quantiles\n",
    "df_5min_quantil1 = df_procesado_5min.quantile(0.25)\n",
    "df_5min_quantil3 = df_procesado_5min.quantile(0.75)\n",
    "df_1hora_quantil1 = df_procesado_1hora.quantile(0.25)\n",
    "df_1hora_quantil3 = df_procesado_1hora.quantile(0.75)\n",
    "df_5min['q1'] = df_5min_quantil1\n",
    "df_5min['q3'] = df_5min_quantil3\n",
    "df_5min.head(10)\n",
    "# df_1hora[['q1', 'q3']] = [df_1hora_quantil1,df_1hora_quantil3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      2621\n",
       "median    2621\n",
       "max       2621\n",
       "min       2621\n",
       "std       2621\n",
       "q1        2076\n",
       "q3        2076\n",
       "dtype: int64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5min.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 15:00:00</th>\n",
       "      <td>0.910574</td>\n",
       "      <td>0.937543</td>\n",
       "      <td>1.281309</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>0.163677</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>1.015671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 16:00:00</th>\n",
       "      <td>0.914551</td>\n",
       "      <td>0.968794</td>\n",
       "      <td>1.234432</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>1.062549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:00:00</th>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.781286</td>\n",
       "      <td>1.328186</td>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.103357</td>\n",
       "      <td>0.718783</td>\n",
       "      <td>0.859414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 18:00:00</th>\n",
       "      <td>0.918940</td>\n",
       "      <td>0.937543</td>\n",
       "      <td>1.312560</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.125242</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>1.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 19:00:00</th>\n",
       "      <td>0.874715</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.250057</td>\n",
       "      <td>0.359391</td>\n",
       "      <td>0.117019</td>\n",
       "      <td>0.781286</td>\n",
       "      <td>0.968794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 20:00:00</th>\n",
       "      <td>0.877129</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>1.140677</td>\n",
       "      <td>0.546900</td>\n",
       "      <td>0.108340</td>\n",
       "      <td>0.796911</td>\n",
       "      <td>0.953169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 21:00:00</th>\n",
       "      <td>0.955519</td>\n",
       "      <td>0.968794</td>\n",
       "      <td>1.296934</td>\n",
       "      <td>0.578151</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>1.031297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 22:00:00</th>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>1.406314</td>\n",
       "      <td>0.359391</td>\n",
       "      <td>0.079524</td>\n",
       "      <td>0.937543</td>\n",
       "      <td>1.031297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 23:00:00</th>\n",
       "      <td>0.915187</td>\n",
       "      <td>0.906291</td>\n",
       "      <td>1.140677</td>\n",
       "      <td>0.406269</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>0.875040</td>\n",
       "      <td>0.953169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 00:00:00</th>\n",
       "      <td>0.989850</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>1.296934</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.085531</td>\n",
       "      <td>0.921917</td>\n",
       "      <td>1.062549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean    median       max       min       std  \\\n",
       "datetime                                                                \n",
       "2020-02-13 15:00:00  0.910574  0.937543  1.281309  0.437520  0.163677   \n",
       "2020-02-13 16:00:00  0.914551  0.968794  1.234432  0.390643  0.201014   \n",
       "2020-02-13 17:00:00  0.788136  0.781286  1.328186  0.515649  0.103357   \n",
       "2020-02-13 18:00:00  0.918940  0.937543  1.312560  0.390643  0.125242   \n",
       "2020-02-13 19:00:00  0.874715  0.875040  1.250057  0.359391  0.117019   \n",
       "2020-02-13 20:00:00  0.877129  0.875040  1.140677  0.546900  0.108340   \n",
       "2020-02-13 21:00:00  0.955519  0.968794  1.296934  0.578151  0.100944   \n",
       "2020-02-13 22:00:00  0.982950  0.984420  1.406314  0.359391  0.079524   \n",
       "2020-02-13 23:00:00  0.915187  0.906291  1.140677  0.406269  0.064902   \n",
       "2020-02-14 00:00:00  0.989850  0.984420  1.296934  0.734409  0.085531   \n",
       "\n",
       "                           q1        q3  \n",
       "datetime                                 \n",
       "2020-02-13 15:00:00  0.843789  1.015671  \n",
       "2020-02-13 16:00:00  0.843789  1.062549  \n",
       "2020-02-13 17:00:00  0.718783  0.859414  \n",
       "2020-02-13 18:00:00  0.843789  1.000046  \n",
       "2020-02-13 19:00:00  0.781286  0.968794  \n",
       "2020-02-13 20:00:00  0.796911  0.953169  \n",
       "2020-02-13 21:00:00  0.890666  1.031297  \n",
       "2020-02-13 22:00:00  0.937543  1.031297  \n",
       "2020-02-13 23:00:00  0.875040  0.953169  \n",
       "2020-02-14 00:00:00  0.921917  1.062549  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Igual con 1hora de dataset\n",
    "df_1hora['q1'] = df_1hora_quantil1\n",
    "df_1hora['q3'] = df_1hora_quantil3\n",
    "df_1hora.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      184\n",
       "median    184\n",
       "max       184\n",
       "min       184\n",
       "std       184\n",
       "q1        184\n",
       "q3        184\n",
       "dtype: int64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1hora.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados en un csv\n",
    "df_5min.to_csv(\"IBI_5min_\"+PACIENTE+\".csv\")\n",
    "df_1hora.to_csv(\"IBI_1hora_\"+PACIENTE+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCHIVOS CSV GENERADOS CON EXITO PARA 5 MIN Y 1 HORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta parte ahora tenemos que calcular los calculos de VFC, para ello se esta utilizando una libreria reada por Digital Biomarkers Discovery, la cual se encargara de procesar los datos por las ventanas de 5 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora generamos el calculo de VFC\n",
    "# Primero importamos la libreria especial de Digital Biomarkers Discovery tiene ya creada\n",
    "import BIL_HRV as bh\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular MeanRR y MeanHR\n",
    "TEMPORAL_NAME = 'test.csv'\n",
    "def calculate_hr(df):\n",
    "    time.sleep(0.2)\n",
    "    df.fillna(0)\n",
    "    # df['ibi'] = df[' ibi']\n",
    "    df[' ibi'] = pd.to_numeric(df[' ibi'], errors='coerce')\n",
    "    df = df.dropna(subset=[' ibi'])\n",
    "    # df = df.drop([' ibi'], axis=1)\n",
    "    df[' ibi'] = df[' ibi'].astype(float)\n",
    "    df.to_csv(TEMPORAL_NAME)\n",
    "    try:\n",
    "        results = bh.hrv(TEMPORAL_NAME)\n",
    "    except Exception as error:\n",
    "    # handle the exception\n",
    "        print(\"An exception occurred:\", error) \n",
    "        print(\"Exception found, Default value response\")\n",
    "        # Crear un diccionario con valores vacíos\n",
    "        results = {\n",
    "            'MeanRR': 0.0,\n",
    "            'MeanHR': 0.0,\n",
    "            'MinHR': 0.0,\n",
    "            'MaxHR': 0.0,\n",
    "            'SDNN': 0.0,\n",
    "            'RMSSD': 0.0,\n",
    "            'NNx': 0.0,\n",
    "            'pNNx': 0.0,\n",
    "            'PowerVLF': 0.0,\n",
    "            'PowerLF': 0.0,\n",
    "            'PowerHF': 0.0,\n",
    "            'PowerTotal': 0.0,\n",
    "            'LF/HF': 0.0,\n",
    "            'PeakVLF': 0.0,\n",
    "            'PeakLF': 0.0,\n",
    "            'PeakHF': 0.0,\n",
    "            'FractionLF': 0.0,\n",
    "            'FractionHF': 0.0\n",
    "        }\n",
    "    # Eliminar el archivo\n",
    "    os.remove(TEMPORAL_NAME)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: max() arg is an empty sequence\n",
      "Exception found, Default value response\n",
      "An exception occurred: A value (1.0) in x_new is below the interpolation range's minimum value (1.046923).\n",
      "Exception found, Default value response\n",
      "An exception occurred: A value (1.0) in x_new is below the interpolation range's minimum value (1.000046).\n",
      "Exception found, Default value response\n",
      "An exception occurred: A value (1.0) in x_new is below the interpolation range's minimum value (1.046923).\n",
      "Exception found, Default value response\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:557\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz\u001b[38;5;241m.\u001b[39mNonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:513\u001b[0m, in \u001b[0;36mDatetimeIndex._parse_with_reso\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_with_reso\u001b[39m(\u001b[38;5;28mself\u001b[39m, label: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 513\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m Timestamp(parsed)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimelike.py:267\u001b[0m, in \u001b[0;36mDatetimeIndexOpsMixin._parse_with_reso\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m    265\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(label)\n\u001b[1;32m--> 267\u001b[0m parsed, reso_str \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_datetime_string_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqstr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m reso \u001b[38;5;241m=\u001b[39m Resolution\u001b[38;5;241m.\u001b[39mfrom_attrname(reso_str)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:435\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:658\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse:  ibi",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:269\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:288\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 288\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:285\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    284\u001b[0m func \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mis_builtin_func(func)\n\u001b[1;32m--> 285\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:428\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(how):\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# TODO: test_resample_apply_with_additional_args fails if we go\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m#  through the non-lambda path, not clear that it should.\u001b[39;00m\n\u001b[1;32m--> 428\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mhow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     result \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39maggregate(func)\n",
      "Cell \u001b[1;32mIn[376], line 7\u001b[0m, in \u001b[0;36mcalculate_hr\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df['ibi'] = df[' ibi']\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ibi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m ibi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ibi\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:559\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz\u001b[38;5;241m.\u001b[39mNonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disallow_mismatched_indexing(parsed)\n",
      "\u001b[1;31mKeyError\u001b[0m: ' ibi'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:557\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz\u001b[38;5;241m.\u001b[39mNonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:513\u001b[0m, in \u001b[0;36mDatetimeIndex._parse_with_reso\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_with_reso\u001b[39m(\u001b[38;5;28mself\u001b[39m, label: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 513\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m Timestamp(parsed)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimelike.py:267\u001b[0m, in \u001b[0;36mDatetimeIndexOpsMixin._parse_with_reso\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m    265\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(label)\n\u001b[1;32m--> 267\u001b[0m parsed, reso_str \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_datetime_string_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqstr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m reso \u001b[38;5;241m=\u001b[39m Resolution\u001b[38;5;241m.\u001b[39mfrom_attrname(reso_str)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:435\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:658\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse:  ibi",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:429\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate\u001b[1;34m(self, how, *args, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: how(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 429\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1304\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1304\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:166\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:355\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m     new_res \u001b[38;5;241m=\u001b[39m \u001b[43mcolg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:238\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m--> 238\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:316\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 316\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:274\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_named\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# result is a dict whose keys are the elements of result_index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:412\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_named\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m--> 412\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m output \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(output)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:428\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(how):\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# TODO: test_resample_apply_with_additional_args fails if we go\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m#  through the non-lambda path, not clear that it should.\u001b[39;00m\n\u001b[1;32m--> 428\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mhow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     result \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39maggregate(func)\n",
      "Cell \u001b[1;32mIn[376], line 7\u001b[0m, in \u001b[0;36mcalculate_hr\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df['ibi'] = df[' ibi']\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ibi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m ibi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ibi\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:559\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz\u001b[38;5;241m.\u001b[39mNonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disallow_mismatched_indexing(parsed)\n",
      "\u001b[1;31mKeyError\u001b[0m: ' ibi'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[377], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m df_procesado_5min\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     resampled \u001b[38;5;241m=\u001b[39m \u001b[43mdf_procesado_5min_HR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_hr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:332\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     how \u001b[38;5;241m=\u001b[39m func\n\u001b[1;32m--> 332\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_groupby_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:440\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate\u001b[1;34m(self, how, *args, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m         result \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39maggregate(how, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;66;03m# we have a non-reducing function; try to evaluate\u001b[39;00m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;66;03m# alternatively we want to evaluate only a column of the input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m#  on Series, raising AttributeError or KeyError\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m#  (depending on whether the column lookup uses getattr/__getitem__)\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust produce aggregated value\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;66;03m# raised in _aggregate_named\u001b[39;00m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;66;03m# see test_apply_without_aggregation, test_apply_with_mutated_index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[376], line 4\u001b[0m, in \u001b[0;36mcalculate_hr\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_hr\u001b[39m(df):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# df['ibi'] = df[' ibi']\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# Resamplear el DataFrame a 5 minutos y aplicar la función\n",
    "# Or if you are using > Python 3.11:\n",
    "df_procesado_5min\n",
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    resampled = df_procesado_5min_HR.apply(calculate_hr).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los resultados al DataFrame original\n",
    "df_resampled = df_procesado_5min_HR.mean()\n",
    "\n",
    "df_resampled['MeanRR'] = resampled['MeanRR']\n",
    "df_resampled['MeanHR'] = resampled['MeanHR']\n",
    "df_resampled['MinHR'] = resampled['MinHR']\n",
    "df_resampled['MaxHR'] = resampled['MaxHR']\n",
    "df_resampled['SDNN'] = resampled['SDNN']\n",
    "df_resampled['RMSSD'] = resampled['RMSSD']\n",
    "df_resampled['NNx'] = resampled['NNx']\n",
    "df_resampled['pNNx'] = resampled['pNNx']\n",
    "df_resampled['PowerVLF'] = resampled['PowerVLF']\n",
    "df_resampled['PowerLF'] = resampled['PowerLF']\n",
    "df_resampled['PowerHF'] = resampled['PowerHF']\n",
    "df_resampled['PowerTotal'] = resampled['PowerTotal']\n",
    "df_resampled['LF/HF'] = resampled['LF/HF']\n",
    "df_resampled['PeakVLF'] = resampled['PeakVLF']\n",
    "df_resampled['PeakLF'] = resampled['PeakLF']\n",
    "df_resampled['PeakHF'] = resampled['PeakHF']\n",
    "df_resampled['FractionLF'] = resampled['FractionLF']\n",
    "df_resampled['FractionHF'] = resampled['FractionHF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ibi</th>\n",
       "      <th>MeanRR</th>\n",
       "      <th>MeanHR</th>\n",
       "      <th>MinHR</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>SDNN</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>NNx</th>\n",
       "      <th>pNNx</th>\n",
       "      <th>PowerVLF</th>\n",
       "      <th>PowerLF</th>\n",
       "      <th>PowerHF</th>\n",
       "      <th>PowerTotal</th>\n",
       "      <th>LF/HF</th>\n",
       "      <th>PeakVLF</th>\n",
       "      <th>PeakLF</th>\n",
       "      <th>PeakHF</th>\n",
       "      <th>FractionLF</th>\n",
       "      <th>FractionHF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-05 15:10:00</th>\n",
       "      <td>0.676208</td>\n",
       "      <td>671.8</td>\n",
       "      <td>90.2</td>\n",
       "      <td>78.4</td>\n",
       "      <td>106.1</td>\n",
       "      <td>64.2</td>\n",
       "      <td>85.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1687.27</td>\n",
       "      <td>1165.29</td>\n",
       "      <td>2005.26</td>\n",
       "      <td>4857.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.24</td>\n",
       "      <td>36.75</td>\n",
       "      <td>63.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-05 15:15:00</th>\n",
       "      <td>0.674718</td>\n",
       "      <td>673.8</td>\n",
       "      <td>89.2</td>\n",
       "      <td>84.2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>88.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>484.36</td>\n",
       "      <td>872.94</td>\n",
       "      <td>1671.55</td>\n",
       "      <td>3028.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>34.31</td>\n",
       "      <td>65.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-05 15:20:00</th>\n",
       "      <td>0.706840</td>\n",
       "      <td>707.5</td>\n",
       "      <td>84.8</td>\n",
       "      <td>81.5</td>\n",
       "      <td>89.9</td>\n",
       "      <td>14.9</td>\n",
       "      <td>78.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>73.40</td>\n",
       "      <td>179.95</td>\n",
       "      <td>335.44</td>\n",
       "      <td>588.79</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>34.91</td>\n",
       "      <td>65.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-05 15:25:00</th>\n",
       "      <td>0.700883</td>\n",
       "      <td>700.5</td>\n",
       "      <td>85.7</td>\n",
       "      <td>83.1</td>\n",
       "      <td>88.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>12.59</td>\n",
       "      <td>210.18</td>\n",
       "      <td>115.10</td>\n",
       "      <td>337.87</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>64.62</td>\n",
       "      <td>35.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-05 15:30:00</th>\n",
       "      <td>0.716830</td>\n",
       "      <td>716.1</td>\n",
       "      <td>83.8</td>\n",
       "      <td>80.7</td>\n",
       "      <td>86.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>106.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>63.6</td>\n",
       "      <td>20.86</td>\n",
       "      <td>161.76</td>\n",
       "      <td>2186.96</td>\n",
       "      <td>2369.59</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6.89</td>\n",
       "      <td>93.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ibi  MeanRR  MeanHR  MinHR  MaxHR  SDNN  RMSSD  \\\n",
       "datetime                                                                   \n",
       "2020-07-05 15:10:00  0.676208   671.8    90.2   78.4  106.1  64.2   85.5   \n",
       "2020-07-05 15:15:00  0.674718   673.8    89.2   84.2  101.0  28.2   88.9   \n",
       "2020-07-05 15:20:00  0.706840   707.5    84.8   81.5   89.9  14.9   78.3   \n",
       "2020-07-05 15:25:00  0.700883   700.5    85.7   83.1   88.7  10.2   46.8   \n",
       "2020-07-05 15:30:00  0.716830   716.1    83.8   80.7   86.3  10.6  106.8   \n",
       "\n",
       "                      NNx  pNNx  PowerVLF  PowerLF  PowerHF  PowerTotal  \\\n",
       "datetime                                                                  \n",
       "2020-07-05 15:10:00  34.0  50.0   1687.27  1165.29  2005.26     4857.82   \n",
       "2020-07-05 15:15:00  54.0  54.5    484.36   872.94  1671.55     3028.85   \n",
       "2020-07-05 15:20:00  68.0  43.6     73.40   179.95   335.44      588.79   \n",
       "2020-07-05 15:25:00  28.0  17.8     12.59   210.18   115.10      337.87   \n",
       "2020-07-05 15:30:00  35.0  63.6     20.86   161.76  2186.96     2369.59   \n",
       "\n",
       "                     LF/HF  PeakVLF  PeakLF  PeakHF  FractionLF  FractionHF  \n",
       "datetime                                                                     \n",
       "2020-07-05 15:10:00   0.58     0.02    0.04    0.24       36.75       63.25  \n",
       "2020-07-05 15:15:00   0.52     0.03    0.05    0.20       34.31       65.69  \n",
       "2020-07-05 15:20:00   0.54     0.02    0.06    0.33       34.91       65.09  \n",
       "2020-07-05 15:25:00   1.83     0.03    0.06    0.38       64.62       35.38  \n",
       "2020-07-05 15:30:00   0.07     0.03    0.13    0.18        6.89       93.11  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5711 entries, 2020-07-05 15:10:00 to 2020-07-25 11:00:00\n",
      "Freq: 5T\n",
      "Data columns (total 19 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0    ibi        1123 non-null   float64\n",
      " 1   MeanRR      5711 non-null   float64\n",
      " 2   MeanHR      5711 non-null   float64\n",
      " 3   MinHR       5711 non-null   float64\n",
      " 4   MaxHR       5711 non-null   float64\n",
      " 5   SDNN        5711 non-null   float64\n",
      " 6   RMSSD       5711 non-null   float64\n",
      " 7   NNx         5711 non-null   float64\n",
      " 8   pNNx        5711 non-null   float64\n",
      " 9   PowerVLF    5711 non-null   float64\n",
      " 10  PowerLF     5711 non-null   float64\n",
      " 11  PowerHF     5711 non-null   float64\n",
      " 12  PowerTotal  5711 non-null   float64\n",
      " 13  LF/HF       5696 non-null   float64\n",
      " 14  PeakVLF     5711 non-null   float64\n",
      " 15  PeakLF      5711 non-null   float64\n",
      " 16  PeakHF      5711 non-null   float64\n",
      " 17  FractionLF  5696 non-null   float64\n",
      " 18  FractionHF  5696 non-null   float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 892.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1123 entries, 2020-07-05 15:10:00 to 2020-07-25 11:00:00\n",
      "Data columns (total 19 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0    ibi        1123 non-null   float64\n",
      " 1   MeanRR      1123 non-null   float64\n",
      " 2   MeanHR      1123 non-null   float64\n",
      " 3   MinHR       1123 non-null   float64\n",
      " 4   MaxHR       1123 non-null   float64\n",
      " 5   SDNN        1123 non-null   float64\n",
      " 6   RMSSD       1123 non-null   float64\n",
      " 7   NNx         1123 non-null   float64\n",
      " 8   pNNx        1123 non-null   float64\n",
      " 9   PowerVLF    1123 non-null   float64\n",
      " 10  PowerLF     1123 non-null   float64\n",
      " 11  PowerHF     1123 non-null   float64\n",
      " 12  PowerTotal  1123 non-null   float64\n",
      " 13  LF/HF       1108 non-null   float64\n",
      " 14  PeakVLF     1123 non-null   float64\n",
      " 15  PeakLF      1123 non-null   float64\n",
      " 16  PeakHF      1123 non-null   float64\n",
      " 17  FractionLF  1108 non-null   float64\n",
      " 18  FractionHF  1108 non-null   float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 175.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_resampled = df_resampled.dropna(subset=[' ibi'])\n",
    "df_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.to_csv(\"IBI_5min_hr_data_\"+PACIENTE+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
